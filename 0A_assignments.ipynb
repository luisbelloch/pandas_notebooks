{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prácticas\n",
    "\n",
    "_Máster Big Data Analytics 2015/2016_  \n",
    "_Luis Belloch luisbelloch@gmail.com_  \n",
    "_Universidad Politécnica de Valencia_  \n",
    "\n",
    "El objetivo de la práctica es aprender a trasladar a Spark pequeños prototipos de algoritmos de cálculo que previamente hemos visto en clase mediante Pandas.\n",
    "\n",
    "Es importante señalar que la implementación de este documento sólo se incluye como referencia para poder entender los cálculos. Para los ejercicios únicamente puede utilizarse `PySpark` y la librería estándar de Python. Opcionalmente puedes hacer uso tambien de `Spark SQL`, pero no se permite instalar terceras librerías a no ser que el ejercicio lo indique.\n",
    "\n",
    "Los ejercicios específicos que debe realizar cada grupo son:\n",
    "\n",
    "* Diploma: 1, 2 y 4\n",
    "* Máster 2016: todos\n",
    "* Máster 2015: sólo 3 y 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.\n",
    "\n",
    "1. Mediante Pandas y haciendo uso de la librería ` pandas.io.data.DataReader` obten los datos de prueba para los simbolos `GOOG`, `AAPL` y `MSFT`.\n",
    "2. Guarda los objetos de Pandas en formato CSV separado por comas.\n",
    "3. Escribe un pequeño programa en Spark que lea los datos, separe por comas y elimine la primera de las filas en el caso de que el CSV contenga los nombres de las columnas.\n",
    "4. Mediante Spark, filtra los datos de los años 2015 y 2016.\n",
    "5. Filtra los datos correspondientes a enero de 2016 mediante Pandas.\n",
    "\n",
    "Recuerda que puedes descargar un trozo del archivo como referencia mediante `curl` y `head`, desde Yahoo:\n",
    "\n",
    "```\n",
    "$ curl --silent wget ichart.yahoo.com/table.csv?s=GOOG | head\n",
    "Date,Open,High,Low,Close,Volume,Adj Close\n",
    "2016-07-08,699.50,705.710022,696.434998,705.630005,1571400,705.630005\n",
    "2016-07-07,698.080017,698.200012,688.215027,695.359985,1303100,695.359985\n",
    "2016-07-06,689.97998,701.679993,689.090027,697.77002,1408600,697.77002\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo uso únicamente de Spark / Spark SQL:\n",
    "\n",
    "1. Carga los datos para `MSFT` desde archivo descargado en el ejercicio 1.\n",
    "2. Obtén el retorno entre los días 15 y 16 de junio del 2016. Recuerda que el retorno entre $t-1$ y $t$ lo definimos como $R_t = \\frac{P_t - P_{t-1}}{P_{t-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014087341517408092"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pandas.io.data as web\n",
    "from datetime import datetime\n",
    "msft = web.DataReader(\"MSFT\", \"google\", datetime(2015, 1, 1), datetime(2016, 12, 31))\n",
    "msft.Close[\"2016-06-15\":\"2016-06-16\"].pct_change()[-1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante: sólo alumnos de máster.**\n",
    "\n",
    "Haciendo uso únicamente de Spark / Spark SQL, extrae una media del precio de cierre por cada cuatrimestre para 2015 y 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-03-31    43.535246\n",
       "2015-06-30    45.628095\n",
       "2015-09-30    44.904375\n",
       "2015-12-31    52.622187\n",
       "2016-03-31    52.421803\n",
       "2016-06-30    51.964687\n",
       "2016-09-30    54.102000\n",
       "Freq: Q-DEC, Name: Close, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft.Close.resample(\"Q\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Haciendo uso únicamente de Spark / Spark SQL, computa el valor de un portfolio a final de mes. Recuerda que el retorno del porfolio para un periodo se define como:\n",
    "\n",
    "$R_{p,t} = \\sum\\limits_{i=1}^n x_i R_{i,t}$\n",
    "\n",
    "donde el porcentaje de participación en el portfolio es $x_n : x_1 + ... + x_n = 1$ y $R_{i,t}$ es cada retorno mensual de cada activo del portfolio.\n",
    "\n",
    "Conociendo esto es posible extraer el valor del portfolio al final del mes $t$, donde $t$ es\n",
    "\n",
    "$V_t = V_{t-1}(1 + R_{p,t})$\n",
    "\n",
    "\n",
    "El portfolio de inicio tiene 10 acciones de `MSFT` y 10 acciones de `AAPL`, ambas compradas el 30 de marzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.049999999999997, 109.56]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft = web.DataReader(\"MSFT\", \"google\", datetime(2015, 12, 25), datetime(2016, 12, 31))\n",
    "aapl = web.DataReader(\"AAPL\", \"google\", datetime(2015, 12, 25), datetime(2016, 12, 31))\n",
    "[msft.Close['2016-03-30'], aapl.Close['2016-03-30']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los precios al final de més, donde computaremos el valor del portfolio, son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.869999999999997, 93.739999999999995]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[msft.Close['2016-04-29'], aapl.Close['2016-04-29']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que podemos calcular `initial_portfolio_value` de forma simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646.0999999999999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_shares = 10\n",
    "aapl_shares = 10\n",
    "initial_portfolio_value = (msft_shares * msft.Close['2016-03-30']) + (aapl_shares * aapl.Close['2016-03-30'])\n",
    "initial_portfolio_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos computar el peso relativo de cada inversión en el total. Observa que sumando ambos pesos nos da un 100% (puede resultarte interesante realizar esta comprobación en Spark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3344268270457445, 0.66557317295425544, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_msft = (msft_shares * msft.Close['2016-03-30']) / initial_portfolio_value\n",
    "x_aapl = (aapl_shares * aapl.Close['2016-03-30']) / initial_portfolio_value\n",
    "[x_msft, x_aapl, x_msft+x_aapl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde aqui solo nos queda calcular el retorno de cada uno de los activos y el del propio portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.094096276112624833, -0.14439576487769268]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_msft = msft.Close['2016-04-29'] / msft.Close['2016-03-30'] - 1\n",
    "ret_aapl = aapl.Close['2016-04-29'] / aapl.Close['2016-03-30'] - 1\n",
    "[ret_msft, ret_aapl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12757426644796796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_returns = (x_msft*ret_msft) + (x_aapl*ret_aapl)\n",
    "portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, el valor del portfolio al final del mes $t$ se puede obtener mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436.0999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = initial_portfolio_value * (1 + portfolio_returns)\n",
    "vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "**Importante: sólo alumnos de máster.**\n",
    "\n",
    "Haciendo uso de Spark, computa la pérdida máxima sobre una cartera con un valor X y una probabilidad del 5%, para una fecha determinada.\n",
    "\n",
    "El _valor en riesgo_ de una cartera es una medida que nos permite cuantificar las pérdidas en una inversión haciendo uso de herramientas estadísticas básicas. Para simplificar el ejercicio asumiremos que nuestra cartera esta compuesta de 1000 acciones de `AAPL` compradas a fecha de cierre del día 2 de febrero de 2015, por un valor de 106271.212€.\n",
    "\n",
    "En este ejercicio calcularemos cúanto perderíamos el día siguiente con una probabilidad del 95%. Estadísticamente VaR se puede definir como:\n",
    "\n",
    "${VaR} = P - P \\cdot (\\alpha(1-c) + 1)$, siendo $c$ el intervalo de confianza\n",
    "\n",
    "Lo primero que haremos será obtener los precios históricos de cierre para `AAPL` desde Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.27121200000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.io.data import DataReader\n",
    "aapl = DataReader('aapl', 'yahoo')\n",
    "prices = aapl[\"Adj Close\"]\n",
    "prices[\"2015-01-02\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aqui podemos calcular el valor del portfolio en esa fecha. Como el porfolio está compuesto de un solo activo, el cálculo es muy sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106271.212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares = 1000\n",
    "portfolio_value = shares * prices.ix['2015-1-02']\n",
    "portfolio_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente que realizaremos será computar los retornos diarios para toda la serie de valores historicos. Recuerda que estamos utilizando la columna `Adj Close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2016-07-27    0.062940\n",
       "2016-07-28    0.013411\n",
       "2016-07-29   -0.001247\n",
       "Name: Adj Close, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def daily_returns(closes):\n",
    "    return np.log(closes / closes.shift(1))\n",
    "\n",
    "returns = daily_returns(prices)\n",
    "returns[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde aqui únicamente nos queda extraer el z-score a aplicar y sustituir valores en la fórmula de VaR descrita arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939.4127308934367"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "z_score = norm.ppf(0.95) # loc:0 (µ), scale: 1 (σ)\n",
    "alpha = z_score * returns.std()\n",
    "value_at_risk = portfolio_value * alpha\n",
    "value_at_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el ejercicio puedes utilizar una constante para `z-score` en lugar de calcularlo dentro del proceso. Igualmente es importante que no hagas uso de numpy o scipy para realizar los cálculos en Spark."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
