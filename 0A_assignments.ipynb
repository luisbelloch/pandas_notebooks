{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prácticas\n",
    "\n",
    "_Máster Big Data Analytics 2015 - 2018_  \n",
    "_Luis Belloch bigdata@luisbelloch.es_  \n",
    "_Universidad Politécnica de Valencia_  \n",
    "\n",
    "El objetivo de la práctica es aprender a trasladar a Spark pequeños prototipos de algoritmos de cálculo que previamente hemos visto en clase mediante Pandas.\n",
    "\n",
    "**IMPORTANTE**: \n",
    "\n",
    "1. La implementación de este documento sólo se incluye como referencia para poder entender los cálculos. Para los ejercicios únicamente puede utilizarse `PySpark` y la librería estándar de Python. Opcionalmente puedes hacer uso tambien de `Spark SQL`, pero no se permite utilizar `pandas` a no ser que el ejercicio lo indique. En algunos ejercicios se utiliza `stock_prices` para cargar los datos. Es sólo un ejemplo, debes utilizar Spark para la carga de datos.\n",
    "2. Es posible obtener resultados ligeramente diferentes a los obtenidos mediante Pandas debido a errores de precisión.\n",
    "3. Para el desarrollo del ejercicio puedes usar notebooks de python, pero debes entregar los ejercicios **en un único archivo .py** donde cada función corresponde a un ejercicio:\n",
    "\n",
    "```\n",
    "# ejercicios.py\n",
    "\n",
    "def ejercicio1():\n",
    "    ...\n",
    "    \n",
    "def ejercicio2():\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "**1 punto**\n",
    "\n",
    "1. Mediante Pandas únicamente, y haciendo uso de `stock_prices` obten los datos de prueba para los simbolos `GOOG`, `AAPL` y `MSFT`.\n",
    "2. Guarda los objetos de Pandas en formato CSV separado por comas.\n",
    "3. Escribe un pequeño programa en Spark que lea los datos en CSV, separe por comas y elimine la primera de las filas en el caso de que el CSV contenga los nombres de las columnas.\n",
    "4. Mediante Spark, filtra los datos de los años 2015 y 2016.\n",
    "\n",
    "Recuerda que los datos de ejemplo están en la carpeta `data`, tanto en formato `MessagePack` como `CSV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "**2 puntos**\n",
    "\n",
    "Haciendo uso únicamente de Spark / Spark SQL:\n",
    "\n",
    "1. Carga los datos para `MSFT` desde archivo descargado en el ejercicio 1.\n",
    "2. Obtén el retorno entre los días 15 y 16 de junio del 2016. Recuerda que el retorno entre $t-1$ y $t$ lo definimos como $R_t = \\frac{P_t - P_{t-1}}{P_{t-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014087341517408092"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sample_data import stock_prices\n",
    "from datetime import datetime, timedelta\n",
    "msft = stock_prices(\"msft\")\n",
    "msft.Close[\"2016-06-15\":\"2016-06-16\"].pct_change()[-1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "**2 puntos**\n",
    "\n",
    "Haciendo uso únicamente de Spark / Spark SQL, extrae una media del precio de cierre por cada cuatrimestre para 2015 y 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2010-03-31    29.277672\n",
       "2010-06-30    27.961838\n",
       "2010-09-30    24.759765\n",
       "2010-12-31    26.344394\n",
       "2011-03-31    27.011461\n",
       "2011-06-30    25.078769\n",
       "2011-09-30    26.069924\n",
       "2011-12-31    26.055923\n",
       "2012-03-31    30.469769\n",
       "2012-06-30    30.444923\n",
       "2012-09-30    30.300185\n",
       "2012-12-31    27.941691\n",
       "2013-03-31    27.682948\n",
       "2013-06-30    32.784046\n",
       "2013-09-30    32.922045\n",
       "2013-12-31    36.352530\n",
       "2014-03-31    37.516328\n",
       "2014-06-30    40.459523\n",
       "2014-09-30    44.576417\n",
       "2014-12-31    46.968864\n",
       "2015-03-31    43.627812\n",
       "2015-06-30    45.565231\n",
       "2015-09-30    44.862045\n",
       "2015-12-31    52.684621\n",
       "2016-03-31    52.444692\n",
       "2016-06-30    51.970154\n",
       "2016-09-30    56.385606\n",
       "2016-12-31    60.198462\n",
       "2017-03-31    64.043231\n",
       "2017-06-30    68.611538\n",
       "2017-09-30    72.984615\n",
       "2017-12-31    82.100462\n",
       "2018-03-31    91.336308\n",
       "2018-06-30    96.589298\n",
       "Freq: Q-DEC, Name: Close, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft.Close.resample(\"Q\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "**2 puntos**\n",
    "\n",
    "Haciendo uso únicamente de Spark / Spark SQL, computa el valor de un portfolio a final de mes. Recuerda que el retorno del porfolio para un periodo se define como:\n",
    "\n",
    "$R_{p,t} = \\sum\\limits_{i=1}^n x_i R_{i,t}$\n",
    "\n",
    "donde el porcentaje de participación en el portfolio es $x_n : x_1 + ... + x_n = 1$ y $R_{i,t}$ es cada retorno mensual de cada activo del portfolio.\n",
    "\n",
    "Conociendo esto es posible extraer el valor del portfolio al final del mes $t$, donde $t$ es\n",
    "\n",
    "$V_t = V_{t-1}(1 + R_{p,t})$\n",
    "\n",
    "\n",
    "El portfolio de inicio tiene 10 acciones de `MSFT` y 10 acciones de `AAPL`, ambas compradas el 30 de marzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.05, 109.56]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft = stock_prices('msft')\n",
    "aapl = stock_prices('aapl')\n",
    "[msft.Close['2016-03-30'], aapl.Close['2016-03-30']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los precios al final de més, donde computaremos el valor del portfolio, son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.87, 93.74]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[msft.Close['2016-04-29'], aapl.Close['2016-04-29']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que podemos calcular `initial_portfolio_value` de forma simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_shares = 10\n",
    "aapl_shares = 10\n",
    "initial_portfolio_value = (msft_shares * msft.Close['2016-03-30']) + (aapl_shares * aapl.Close['2016-03-30'])\n",
    "initial_portfolio_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos computar el peso relativo de cada inversión en el total. Observa que sumando ambos pesos nos da un 100% (puede resultarte interesante realizar esta comprobación en Spark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3344268270457445, 0.6655731729542554, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_msft = (msft_shares * msft.Close['2016-03-30']) / initial_portfolio_value\n",
    "x_aapl = (aapl_shares * aapl.Close['2016-03-30']) / initial_portfolio_value\n",
    "[x_msft, x_aapl, x_msft+x_aapl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde aqui solo nos queda calcular el retorno de cada uno de los activos y el del propio portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.09409627611262483, -0.14439576487769268]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_msft = msft.Close['2016-04-29'] / msft.Close['2016-03-30'] - 1\n",
    "ret_aapl = aapl.Close['2016-04-29'] / aapl.Close['2016-03-30'] - 1\n",
    "[ret_msft, ret_aapl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12757426644796796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_returns = (x_msft*ret_msft) + (x_aapl*ret_aapl)\n",
    "portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, el valor del portfolio al final del mes $t$ se puede obtener mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = initial_portfolio_value * (1 + portfolio_returns)\n",
    "vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "**3 puntos**\n",
    "\n",
    "Haciendo uso de Spark, computa la pérdida máxima sobre una cartera con un valor X y una probabilidad del 5%, para una fecha determinada.\n",
    "\n",
    "El _valor en riesgo_ de una cartera es una medida que nos permite cuantificar las pérdidas en una inversión haciendo uso de herramientas estadísticas básicas. Para simplificar el ejercicio asumiremos que nuestra cartera esta compuesta de 1000 acciones de `AAPL` compradas a fecha de cierre del día 2 de febrero de 2015, por un valor de 106271.212€.\n",
    "\n",
    "En este ejercicio calcularemos cúanto perderíamos el día siguiente con una probabilidad del 95%. Estadísticamente VaR se puede definir como:\n",
    "\n",
    "${VaR} = P - P \\cdot (\\alpha(1-c) + 1)$, siendo $c$ el intervalo de confianza\n",
    "\n",
    "Lo primero que haremos será obtener los precios históricos de cierre para `AAPL` desde Google Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = stock_prices('aapl')\n",
    "prices = aapl.Close\n",
    "prices[\"2015-01-02\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aqui podemos calcular el valor del portfolio en esa fecha. Como el porfolio está compuesto de un solo activo, el cálculo es muy sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109330.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares = 1000\n",
    "portfolio_value = shares * prices.loc['2015-1-02']\n",
    "portfolio_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente que realizaremos será computar los retornos diarios para toda la serie de valores historicos. Recuerda que estamos utilizando la columna `Adj Close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2018-06-14    0.000524\n",
       "2018-06-15   -0.010326\n",
       "2018-06-18   -0.000530\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def daily_returns(closes):\n",
    "    return np.log(closes / closes.shift(1))\n",
    "\n",
    "returns = daily_returns(prices)\n",
    "returns[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde aqui únicamente nos queda extraer el z-score a aplicar y sustituir valores en la fórmula de VaR descrita arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2814.289349489219"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "z_score = norm.ppf(0.95) # loc:0 (µ), scale: 1 (σ)\n",
    "alpha = z_score * returns.std()\n",
    "value_at_risk = portfolio_value * alpha\n",
    "value_at_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el ejercicio puedes utilizar una constante para `z-score` en lugar de calcularlo dentro del proceso. Igualmente es importante que no hagas uso de numpy o scipy para realizar los cálculos en Spark."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
